# HohhotBrain

## LLM-based Hohhot AI Smart Brain (åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å‘¼å’Œæµ©ç‰¹AIæ™ºæ…§å¤§è„‘)



<p align="center">
    <img src="./figure/HohhotBrain.png" width=400px/>
</p>



## ç®€ä»‹
è¿‘å¹´æ¥ï¼Œéšç€äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œå…¶åœ¨å„ä¸ªé¢†åŸŸå±•ç¤ºå‡ºäº†å·¨å¤§çš„æ½œåŠ›å’Œåº”ç”¨å‰æ™¯ã€‚åŸå¸‚æ–‡åŒ–ä½œä¸ºäººç±»ç¤¾ä¼šå‘å±•çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼Œä¹Ÿå¼€å§‹é€æ¸å—åˆ°äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å…³æ³¨ã€‚åŸå¸‚æ–‡åŒ–æ˜¯åŸå¸‚çš„çµé­‚ï¼Œæ˜¯åŸå¸‚ä¸å…¶ä»–åœ°åŒºçš„å·®å¼‚å’Œç‰¹è‰²æ‰€åœ¨ã€‚å®ƒåŒ…æ‹¬åŸå¸‚çš„å†å²æ–‡åŒ–ã€ä¼ ç»Ÿè‰ºæœ¯ã€åœ°æ–¹ç¾é£Ÿã€æ°‘ä¿—ä¹ æƒ¯ç­‰å„ä¸ªæ–¹é¢çš„å†…å®¹ã€‚ä¼ æ‰¿å’Œå‘å±•åŸå¸‚æ–‡åŒ–å¯¹äºåŸå¸‚çš„å¯æŒç»­å‘å±•å’Œæå‡åŸå¸‚å½¢è±¡å…·æœ‰é‡è¦æ„ä¹‰ã€‚å¦å¤–ï¼Œå¤§è¯­è¨€æ¨¡å‹æ˜¯ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ æŠ€æœ¯çš„è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹ï¼Œå®ƒå¯ä»¥é€šè¿‡å¤§é‡çš„è¯­æ–™åº“æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä»è€Œå…·å¤‡äº†å¼ºå¤§çš„è¯­ä¹‰ç†è§£å’Œç”Ÿæˆèƒ½åŠ›ã€‚è¿™ç§æ¨¡å‹å¯ä»¥è‡ªåŠ¨åˆ†æå’Œç”Ÿæˆä¸è‡ªç„¶è¯­è¨€ç›¸å…³çš„å†…å®¹ï¼Œå¦‚æ–‡ç« ã€å¯¹è¯ã€ç¿»è¯‘ç­‰ã€‚åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åŸå¸‚æ–‡åŒ–AIæ¨¡å‹çš„å¼€å‘æ—¨åœ¨åˆ©ç”¨äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œæ¨åŠ¨åŸå¸‚æ–‡åŒ–çš„æ•°å­—åŒ–è½¬å‹å’Œåˆ›æ–°ã€‚é€šè¿‡å¯¹å¤§é‡åŸå¸‚æ–‡åŒ–æ•°æ®è¿›è¡Œè®­ç»ƒå’Œåˆ†æï¼Œæ¨¡å‹å¯ä»¥æ·±å…¥æŒ–æ˜å’Œç†è§£åŸå¸‚çš„å†å²æ–‡åŒ–ã€ä¼ ç»Ÿè‰ºæœ¯ä»¥åŠä¸åŸå¸‚ç›¸å…³çš„å„ç§æ–‡åŒ–å…ƒç´ ã€‚å¯ä»¥è‡ªåŠ¨ç”Ÿæˆä¸åŸå¸‚æ–‡åŒ–ç›¸å…³çš„æ–‡ç« ã€æ¨èæ—…æ¸¸æ™¯ç‚¹ã€ä»‹ç»åœ°æ–¹ç‰¹è‰²ç­‰å†…å®¹ï¼Œä¸ºåŸå¸‚è§„åˆ’ã€æ—…æ¸¸æ¨å¹¿ã€æ–‡åŒ–äº¤æµç­‰é¢†åŸŸæä¾›é‡è¦çš„æ™ºèƒ½åŒ–è§£å†³æ–¹æ¡ˆã€‚

åŸºäºæ­¤ï¼Œæœ¬é¡¹ç›®é€šè¿‡æ·±å…¥ç ”ç©¶å‘¼å’Œæµ©ç‰¹åŸå¸‚çš„å†å²ã€æ–‡åŒ–å’Œç¤¾ä¼šç‰¹ç‚¹ï¼Œæ”¶é›†æ•´ç†å¤§è§„æ¨¡çš„å‘¼å’Œæµ©ç‰¹æ–‡åŒ–æ—…æ¸¸ç›¸å…³çš„è®­ç»ƒæ•°æ®ï¼Œç»“åˆå¤§è§„æ¨¡æ•°æ®çš„è®­ç»ƒå’Œæ¨¡å‹çš„ä¼˜åŒ–ï¼Œå®ç°äº†â€œåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å‘¼å’Œæµ©ç‰¹AIæ™ºæ…§å¤§è„‘â€ã€‚è¯¥æ¨¡å‹å¯ä»¥æ›´å¥½åœ°ç†è§£å‘¼å’Œæµ©ç‰¹åŸå¸‚æ–‡åŒ–çš„å†…æ¶µå’Œç‰¹ç‚¹ï¼Œä¸ºå‘¼å’Œæµ©ç‰¹åŸå¸‚çš„æ–‡åŒ–ä¼ æ‰¿å’Œå‘å±•æä¾›é‡è¦çš„æ”¯æŒå’ŒæŒ‡å¯¼ã€‚

ç»¼ä¸Šï¼Œâ€œåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å‘¼å’Œæµ©ç‰¹AIæ™ºæ…§å¤§è„‘â€çš„æ¨å‡ºå°†ä¸ºå‘¼å’Œæµ©ç‰¹åŸå¸‚æ–‡åŒ–ç ”ç©¶å’Œä¼ æ’­å¸¦æ¥æ–°çš„æœºé‡å’ŒæŒ‘æˆ˜ã€‚å®ƒæœ‰åŠ©äºåŠ å¿«å‘¼å’Œæµ©ç‰¹åŸå¸‚æ–‡åŒ–çš„æ•°å­—åŒ–è¿›ç¨‹ï¼Œæå‡åŸå¸‚å½¢è±¡å’Œå“ç‰Œä»·å€¼ï¼Œä¿ƒè¿›åŸå¸‚çš„å¯æŒç»­å‘å±•å’Œå›½é™…äº¤æµã€‚åŒæ—¶ï¼Œå®ƒä¹Ÿä¸ºäººä»¬æä¾›äº†æ›´ä¾¿æ·å’Œä¸ªæ€§åŒ–çš„åŸå¸‚æ–‡åŒ–ä½“éªŒå’ŒæœåŠ¡ï¼Œæé«˜äº†åŸå¸‚æ–‡åŒ–çš„æ™®åŠåº¦å’Œå½±å“åŠ›ã€‚



æœ¬é¡¹ç›®åŸºäºLangchainä¸ºåŸºç¡€ï¼Œç»“åˆLLMå¤§è¯­è¨€æ¨¡å‹ï¼Œå¹¶ä»¥ä¸°å¯Œçš„å‘¼å’Œæµ©ç‰¹åŸå¸‚æ•°æ®ä¸ºåŸºç¡€æ„å»ºäº†æœ¬åœ°é—®ç­”çŸ¥è¯†åº“æ¥å®£ä¼ å‘¼å’Œæµ©ç‰¹çš„åŸå¸‚æ–‡åŒ–ã€‚
* LangChainæ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ChatGPTï¼‰ç”¨äºæ„å»ºç«¯åˆ°ç«¯è¯­è¨€æ¨¡å‹åº”ç”¨çš„Pythonæ¡†æ¶ã€‚[Langchain](https://github.com/langchain-ai/langchain)    
* ç»è¿‡ç™¾ä¸‡è§„æ¨¡å¿ƒç†å’¨è¯¢é¢†åŸŸä¸­æ–‡é•¿æ–‡æœ¬æŒ‡ä»¤ä¸å¤šè½®å…±æƒ…å¯¹è¯æ•°æ®è”åˆæŒ‡ä»¤å¾®è°ƒçš„ [InternLMå¤§è¯­è¨€æ¨¡å‹](https://github.com/InternLM/InternLM)   

æˆ‘ä»¬æœŸæœ›ï¼Œ**Langchainæ„å»ºæœ¬åœ°çŸ¥è¯†åº“** å¯ä»¥å¸®åŠ©å­¦æœ¯ç•ŒåŠ é€Ÿå¤§æ¨¡å‹åœ¨ç‰¹å®šåŒºåŸŸæ–‡åŒ–å®£ä¼ çš„ç ”ç©¶ä¸åº”ç”¨ã€‚
## æœ€è¿‘æ›´æ–°
- ğŸ‘ğŸ»  2024.3.08ï¼šæˆ‘ä»¬çš„ å‘¼å’Œæµ©ç‰¹AIæ™ºæ…§å¤§è„‘ æ­£å¼å‘å¸ƒï¼ï¼ï¼

   åœ¨å­¦æœ¯ç•Œï¼Œä¸€äº›ç ”ç©¶å›¢é˜Ÿå¼€å§‹å°è¯•å°†Langchainçš„æ€æƒ³åº”ç”¨äºæœ¬åœ°çŸ¥è¯†åº“çš„æ„å»ºã€‚ä»–ä»¬è‡´åŠ›äºé€šè¿‡æ„å»ºçŸ¥è¯†å›¾è°±ã€æ•´åˆé¢†åŸŸä¸“å®¶çŸ¥è¯†ç­‰æ–¹å¼ï¼Œå»ºç«‹èµ·ä¸°å¯Œçš„æœ¬åœ°çŸ¥è¯†åº“ï¼Œå¹¶ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œé—®é¢˜å›ç­”ã€‚è¿™äº›ç ”ç©¶æ—¨åœ¨æé«˜é—®ç­”ç³»ç»Ÿå¯¹ä¸­æ–‡è¯­å¢ƒçš„ç†è§£å’Œå¤„ç†èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å‡†ç¡®åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚æœ¬æ–‡å°±æ˜¯åŸºäºLangchainæ¡†æ¶æ„å»ºæœ¬åœ°çš„çŸ¥è¯†åº“å¹¶æ¥å…¥LLMæ¨¡å‹æ¥æ„å»ºçš„ä¸€ä¸ªåŸºäºè¯­è¨€æ¨¡å‹çš„å‘¼å’Œæµ©ç‰¹AIæ™ºæ…§å¤§è„‘ï¼ŒåŠ©åŠ›å‘¼å’Œæµ©ç‰¹æ–‡åŒ–å®£ä¼ ï¼
<p align="center">
    <img src="./figure/Langchain.jpeg" width=200px/>
</p>

æˆ‘ä»¬é€‰æ‹©äº† [InternLMå¤§è¯­è¨€æ¨¡å‹](https://github.com/InternLM/InternLM) ä½œä¸ºåº•åº§å¤§è¯­è¨€æ¨¡å‹ï¼Œè¿›è¡Œäº†**æœ¬åœ°çŸ¥è¯†åº“çš„æ¥å…¥**ï¼Œæ—¨åœ¨æå‡æ¨¡å‹çš„é’ˆå¯¹å‘¼å’Œæµ©ç‰¹åœ°åŒºçš„äº¤æµé—®ç­”èƒ½åŠ›ã€‚ä¹‹æ‰€ä»¥é€‰æ‹©InternLMæ¨¡å‹åŸå› å¦‚ä¸‹ï¼š
## Introduction

InternLM2 series are released with the following features:

- **200K Context window**: Nearly perfect at finding needles in the haystack with 200K-long context, with leading performance on long-context tasks like LongBench and L-Eval. Try it with [LMDeploy](./chat/lmdeploy.md) for 200K-context inference.

- **Outstanding comprehensive performance**: Significantly better than the last generation in all dimensions, especially in reasoning, math, code, chat experience, instruction following, and creative writing, with leading performance among open-source models in similar sizes. In some evaluations, InternLM2-Chat-20B may match or even surpass ChatGPT (GPT-3.5).

- **Code interpreter & Data analysis**: With code interpreter, InternLM2-Chat-20B obtains compatible performance with GPT-4 on GSM8K and MATH. InternLM2-Chat also provides data analysis capability.

- **Stronger tool use**: Based on better tool utilization-related capabilities in instruction following, tool selection and reflection, InternLM2 can support more kinds of agents and multi-step tool calling for complex tasks. See [examples](./agent/).

## Model Zoo

| Model                      | Transformers(HF)                           | ModelScope(HF)                           | OpenXLab(HF)                           | OpenXLab(Origin)                           | Release Date |
| -------------------------- | ------------------------------------------ | ---------------------------------------- | -------------------------------------- | ------------------------------------------ | ------------ |
| **InternLM2-1.8B**     | [ğŸ¤—internlm2-1.8b](https://huggingface.co/internlm/internlm2-1_8b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-1.8b](https://www.modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-1_8b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-1.8b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-1.8b-original) | 2024-01-31   |
| **InternLM2-Chat-1.8B-SFT**          | [ğŸ¤—internlm2-chat-1.8b-sft](https://huggingface.co/internlm/internlm2-chat-1_8b-sft) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-chat-1.8b-sft](https://www.modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-1_8b-sft/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-1.8b-sft) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-1.8b-sft-original) | 2024-01-31   |
| **InternLM2-Chat-1.8B**          | [ğŸ¤—internlm2-chat-1.8b](https://huggingface.co/internlm/internlm2-chat-1_8b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-chat-1.8b](https://www.modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-1_8b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-1.8b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-1.8b-original) | 2024-02-19   |
| **InternLM2-Base-7B**      | [ğŸ¤—internlm2-base-7b](https://huggingface.co/internlm/internlm2-base-7b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-base-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-base-7b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-7b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-7b-original) | 2024-01-17   |
| **InternLM2-7B**           | [ğŸ¤—internlm2-7b](https://huggingface.co/internlm/internlm2-7b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-7b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-7b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-7b-original) | 2024-01-17   |
| **InternLM2-Chat-7B-SFT**  | [ğŸ¤—internlm2-chat-7b-sft](https://huggingface.co/internlm/internlm2-chat-7b-sft) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-chat-7b-sft](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-7b-sft/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-7b-sft) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-7b-sft-original) | 2024-01-17   |
| **InternLM2-Chat-7B**      | [ğŸ¤—internlm2-chat-7b](https://huggingface.co/internlm/internlm2-chat-7b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-chat-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-7b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-7b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-7b-original) | 2024-01-17   |
| **InternLM2-Base-20B**     | [ğŸ¤—internlm2-base-20b](https://huggingface.co/internlm/internlm2-base-20b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-base-20b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-base-20b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-20b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-20b-original) | 2024-01-17   |
| **InternLM2-20B**          | [ğŸ¤—internlm2-20b](https://huggingface.co/internlm/internlm2-20b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-20b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-20b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-20b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-20b-original) | 2024-01-17   |
| **InternLM2-Chat-20B-SFT** | [ğŸ¤—internlm2-chat-20b-sft](https://huggingface.co/internlm/internlm2-chat-20b-sft) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-chat-20b-sft](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-20b-sft/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-20b-sft) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-20b-sft-original) | 2024-01-17   |
| **InternLM2-Chat-20B**     | [ğŸ¤—internlm2-chat-20b](https://huggingface.co/internlm/internlm2-chat-20b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-chat-20b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-20b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-20b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-20b-original) | 2024-01-17   |


## ä½¿ç”¨æ–¹æ³•
* å…‹éš†æœ¬é¡¹ç›®
```bash
cd ~
git clone https://github.com/AI-S2-Lab/HohhotBrain.git
```
* ä¸‹è½½æ¨¡å‹    
æœ¬é¡¹ç›®ä½¿ç”¨çš„LLMæ¨¡å‹ä¸ºå¤æ—¦å¤§å­¦ç ”å‘çš„InternLMï¼ˆä¹¦ç”ŸÂ·æµ¦è¯­ï¼‰å¤§è¯­è¨€æ¨¡å‹ï¼Œå»ºè®®æ‰‹åŠ¨åœ¨huggingfaceä¸Šä¸‹è½½æ¨¡å‹ä¹Ÿå¯ä»¥gitä¸‹è½½
```
git clone https://huggingface.co/internlm/internlm2-chat-7b
```

* åˆ›å»ºå¹¶æ¿€æ´»condaç¯å¢ƒ    
è¿™é‡Œæˆ‘ä¸åšå…·ä½“çš„è™šæ‹Ÿcondaç¯å¢ƒçš„åˆ›å»º
```
conda activate InternLM
```

* å®‰è£…Langchainç›¸å…³ä¾èµ–
```
pip install langchain==0.0.292
pip install gradio==4.4.0
pip install chromadb==0.4.15
pip install sentence-transformers==2.2.2
pip install unstructured==0.10.30
pip install markdown==3.3.7
```
* ä¸‹è½½å¼€æºè¯å‘é‡æ¨¡å‹    
åŒæ—¶ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨åˆ°å¼€æºè¯å‘é‡æ¨¡å‹ [Sentence Transformer](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2):ï¼ˆæˆ‘ä»¬ä¹Ÿå¯ä»¥é€‰ç”¨åˆ«çš„å¼€æºè¯å‘é‡æ¨¡å‹æ¥è¿›è¡Œ Embeddingï¼Œç›®å‰é€‰ç”¨è¿™ä¸ªæ¨¡å‹æ˜¯ç›¸å¯¹    è½»é‡ã€æ”¯æŒä¸­æ–‡ä¸”æ•ˆæœè¾ƒå¥½çš„ï¼‰

* é¦–å…ˆéœ€è¦ä½¿ç”¨ `huggingface` å®˜æ–¹æä¾›çš„ `huggingface-cli` å‘½ä»¤è¡Œå·¥å…·ã€‚å®‰è£…ä¾èµ–:

```
pip install -U huggingface_hub
```

* ç„¶ååœ¨æ ¹ç›®å½•ä¸‹æ–°å»ºpythonæ–‡ä»¶ `download.py`ï¼Œå¡«å…¥ä»¥ä¸‹ä»£ç ï¼š
```python
import os
* è¿è¡Œdownload.pyè¿›è¡Œä¸‹è½½

# ä¸‹è½½æ¨¡å‹
os.system('huggingface-cli download --resume-download sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 --local-dir /root/data/model/sentence-transformer')
```
* ä¸‹è½½ NLTK ç›¸å…³èµ„æº    
æˆ‘ä»¬åœ¨ä½¿ç”¨å¼€æºè¯å‘é‡æ¨¡å‹æ„å»ºå¼€æºè¯å‘é‡çš„æ—¶å€™ï¼Œéœ€è¦ç”¨åˆ°ç¬¬ä¸‰æ–¹åº“ `nltk` çš„ä¸€äº›èµ„æºã€‚æ­£å¸¸æƒ…å†µä¸‹ï¼Œå…¶ä¼šè‡ªåŠ¨ä»äº’è”ç½‘ä¸Šä¸‹è½½ï¼Œä½†å¯èƒ½ç”±äºç½‘ç»œåŸå› ä¼šå¯¼è‡´ä¸‹è½½ä¸­æ–­ï¼Œæ­¤å¤„æˆ‘ä»¬å¯ä»¥ä»å›½å†…ä»“åº“é•œåƒåœ°å€ä¸‹è½½ç›¸å…³èµ„æºï¼Œä¿å­˜åˆ°æœåŠ¡å™¨ä¸Šã€‚
æˆ‘ä»¬ç”¨ä»¥ä¸‹å‘½ä»¤ä¸‹è½½ nltk èµ„æºå¹¶è§£å‹åˆ°æœåŠ¡å™¨ä¸Šï¼š


```bash
cd /root
git clone https://gitee.com/yzy0612/nltk_data.git  --branch gh-pages
cd nltk_data
mv packages/*  ./
cd tokenizers
unzip punkt.zip
cd ../taggers
unzip averaged_perceptron_tagger.zip
```

* å®‰è£…è¿è¡Œdemoæ‰€éœ€è¦çš„ä¾èµ–
```shell
# å‡çº§pip
python -m pip install --upgrade pip

pip install modelscope==1.9.5
pip install transformers==4.35.2
pip install streamlit==1.24.0
pip install sentencepiece==0.1.99
pip install accelerate==0.24.1
```
   
* å¯åŠ¨æœåŠ¡     
æœ¬é¡¹ç›®æä¾›äº†[run_gradio.py](./run_gradio.py)ä½œä¸ºæ¨¡å‹çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œæ¥é€šè¿‡ python å‘½ä»¤è¿è¡Œï¼Œå³å¯åœ¨æœ¬åœ°å¯åŠ¨çŸ¥è¯†åº“åŠ©æ‰‹çš„ Web Demoï¼Œé»˜è®¤ä¼šåœ¨ 7860 ç«¯å£è¿è¡Œï¼Œæ¥ä¸‹æ¥å°†æœåŠ¡å™¨ç«¯å£æ˜ å°„åˆ°æœ¬åœ°ç«¯å£å³å¯è®¿é—®
```
python run_gradio.py
```

## ç¤ºä¾‹
* æ•´ä½“å¸ƒå±€
<p align="center">
    <img src="./figure/æ•´ä½“å¸ƒå±€.png" width=900px/>
</p>  

* æ ·ä¾‹1ï¼šä»‹ç»ä¸€ä¸‹å‘¼å’Œæµ©ç‰¹çš„æ–‡åŒ–
<p align="center">
    <img src="./figure/æ–‡åŒ–.png" width=900px/>
</p>

* æ ·ä¾‹2ï¼šä»‹ç»ä¸€ä¸‹å‘¼å’Œæµ©ç‰¹çš„å¤§æ˜­å¯º

<p align="center">
    <img src="./figure/å¤§æ˜­å¯º.png" width=900px/>
</p>

* æ ·ä¾‹3ï¼šå†…è’™å¤å¤§å­¦åœ¨å‘¼å’Œæµ©ç‰¹çš„ä½ç½®

<p align="center">
    <img src="./figure/å†…è’™å¤å¤§å­¦.png" width=900px/>
</p>

## å¯¹æ¯”åˆ†æ
#### å†…è’™å¤å¤§å­¦åœ¨å‘¼å’Œæµ©ç‰¹çš„ä½ç½®
* GPT3.5ç”Ÿæˆ
<p align="center">
    <img src="./figure/GPT2.png" width=900px/>
</p>
* æœ¬é¡¹ç›®ç”Ÿæˆ
<p align="center">
    <img src="./figure/å†…è’™å¤å¤§å­¦.png" width=900px/>
</p>

#### ä»‹ç»ä¸€ä¸‹å‘¼å’Œæµ©ç‰¹çš„å¤§æ˜­å¯º
* GPT3.5ç”Ÿæˆ
<p align="center">
    <img src="./figure/GPT1.png" width=900px/>
</p>
* æœ¬é¡¹ç›®ç”Ÿæˆ
<p align="center">
    <img src="./figure/å¤§æ˜­å¯º.png" width=900px/>
</p>
å¯ä»¥çœ‹å‡ºæœ¬é¡¹ç›®åœ¨é’ˆå¯¹å‘¼å’Œæµ©ç‰¹åŒºåŸŸçš„æ–‡åŒ–ä¸Šè¿˜æ˜¯è¾ƒä¸ºå‡†ç¡®çš„ï¼Œç›¸æ¯”äºç«çˆ†GPT3.5è¦æ›´ä¼˜è¶Šã€‚

## å£°æ˜
* æœ¬é¡¹ç›®ä½¿ç”¨äº†IntertnLMæ¨¡å‹çš„æƒé‡ï¼Œéœ€è¦éµå¾ªå…¶[LICENSE](https://github.com/InternLM/InternLM/blob/main/LICENSE)ï¼Œå› æ­¤ï¼Œ**æœ¬é¡¹ç›®ä»…å¯ç”¨äºæ‚¨çš„éå•†ä¸šç ”ç©¶ç›®çš„**ã€‚
* æœ¬é¡¹ç›®æä¾›çš„å¯¹è¯é—®ç­”æ¨¡å‹è‡´åŠ›äºæå‡ç”¨æˆ·å¯¹å‘¼å’Œæµ©ç‰¹åŒºåŸŸçŸ¥è¯†çš„äº†è§£ä»¥åŠä½¿ç”¨Langchainæ¡†æ¶æ„å»ºæœ¬åœ°çŸ¥è¯†åº“çš„ä½¿ç”¨ã€‚æœ¬é¡¹ç›®ä¸ä¿è¯æ¨¡å‹è¾“å‡ºçš„æ–‡æœ¬å®Œå…¨é€‚åˆäºç”¨æˆ·ï¼Œç”¨æˆ·åœ¨ä½¿ç”¨æœ¬æ¨¡å‹æ—¶éœ€è¦æ‰¿æ‹…å…¶å¸¦æ¥çš„æ‰€æœ‰é£é™©ï¼
* æ‚¨ä¸å¾—å‡ºäºä»»ä½•å•†ä¸šã€å†›äº‹æˆ–éæ³•ç›®çš„ä½¿ç”¨ã€å¤åˆ¶ã€ä¿®æ”¹ã€åˆå¹¶ã€å‘å¸ƒã€åˆ†å‘ã€å¤åˆ¶æˆ–åˆ›å»ºHohhotLLMçš„å…¨éƒ¨æˆ–éƒ¨åˆ†è¡ç”Ÿä½œå“ã€‚
* æ‚¨ä¸å¾—åˆ©ç”¨HohhotLLMæ¨¡å‹ä»äº‹ä»»ä½•å±å®³å›½å®¶å®‰å…¨å’Œå›½å®¶ç»Ÿä¸€ã€å±å®³ç¤¾ä¼šå…¬å…±åˆ©ç›Šã€ä¾µçŠ¯äººèº«æƒç›Šçš„è¡Œä¸ºã€‚

## è‡´è°¢
æœ¬é¡¹ç›®ç”±å†…è’™å¤å¤§å­¦è®¡ç®—æœºå­¦é™¢ è¯­éŸ³ç†è§£ä¸ç”Ÿæˆå®éªŒå®¤ï¼ˆ[S2Lab](https://ttslr.github.io)ï¼‰åˆ˜ç‘ ç ”ç©¶å‘˜ä¸»å¯¼å¼€å‘ã€‚

å®éªŒå®¤æœ¬ç§‘ç”Ÿ [@å¾è£å»º](https://github.com/R2-xurongjian) ä¸ºè¯¥é¡¹ç›®ä¸»è¦æˆå‘˜ã€‚

åŒæ—¶è‡´è°¢"**è’™å¤æ–‡æ™ºèƒ½ä¿¡æ¯å¤„ç†æŠ€æœ¯å›½å®¶åœ°æ–¹è”åˆå·¥ç¨‹ç ”ç©¶ä¸­å¿ƒ**","**å†…è’™å¤è‡ªæ²»åŒºè’™å¤æ–‡ä¿¡æ¯å¤„ç†æŠ€æœ¯é‡ç‚¹å®éªŒå®¤å®¤**"å’Œ"**å†…è’™å¤å¤§å­¦è®¡ç®—æœºå­¦é™¢**"çš„å¤§åŠ›æ”¯æŒã€‚

