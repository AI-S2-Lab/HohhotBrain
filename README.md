# HohhotLLM
## AI Assistant for Hohhot City Culture  (å‘¼å’Œæµ©ç‰¹åŸå¸‚æ–‡åŒ–AIåŠ©æ‰‹)
å›½å†…åœ¨å‚ç›´é¢†åŸŸå¤§æ¨¡å‹çš„ç ”ç©¶æ–¹é¢å·²ç»å–å¾—äº†æ˜¾è‘—çš„è¿›å±•ã€‚éšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„ä¸æ–­å‘å±•å’Œè®¡ç®—èƒ½åŠ›çš„æå‡ï¼Œè¶Šæ¥è¶Šå¤šçš„ç ”ç©¶è€…å¼€å§‹å…³æ³¨å¦‚ä½•åˆ©ç”¨å¤§æ¨¡å‹æ¥è§£å†³ç‰¹å®šé¢†åŸŸçš„é—®é¢˜ã€‚
æœ¬é¡¹ç›®åŸºäºLangchainä¸ºåŸºç¡€ï¼Œç»“åˆLLMå¤§è¯­è¨€æ¨¡å‹ï¼Œå¹¶ä»¥ä¸°å¯Œçš„å‘¼å’Œæµ©ç‰¹åŸå¸‚æ•°æ®ä¸ºåŸºç¡€æ„å»ºäº†æœ¬åœ°é—®ç­”çŸ¥è¯†åº“æ¥å®£ä¼ å‘¼å’Œæµ©ç‰¹çš„åŸå¸‚æ–‡åŒ–ã€‚
* LangChainæ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ChatGPTï¼‰ç”¨äºæ„å»ºç«¯åˆ°ç«¯è¯­è¨€æ¨¡å‹åº”ç”¨çš„Pythonæ¡†æ¶ã€‚[Langchain](https://github.com/langchain-ai/langchain)    
* ç»è¿‡ç™¾ä¸‡è§„æ¨¡å¿ƒç†å’¨è¯¢é¢†åŸŸä¸­æ–‡é•¿æ–‡æœ¬æŒ‡ä»¤ä¸å¤šè½®å…±æƒ…å¯¹è¯æ•°æ®è”åˆæŒ‡ä»¤å¾®è°ƒçš„ [InternLMå¤§è¯­è¨€æ¨¡å‹](https://github.com/InternLM/InternLM)   

æˆ‘ä»¬æœŸæœ›ï¼Œ**Langchainæ„å»ºæœ¬åœ°çŸ¥è¯†åº“** å¯ä»¥å¸®åŠ©å­¦æœ¯ç•ŒåŠ é€Ÿå¤§æ¨¡å‹åœ¨ç‰¹å®šåŒºåŸŸæ–‡åŒ–å®£ä¼ çš„ç ”ç©¶ä¸åº”ç”¨ã€‚æœ¬é¡¹ç›®ä¸º **Urban Large Language Model for Hohhot** ã€‚
## æœ€è¿‘æ›´æ–°
- ğŸ‘ğŸ»  2024.3.08ï¼šæˆ‘ä»¬çš„å‘¼å’Œæµ©ç‰¹åŸå¸‚æ–‡åŒ–å¤§æ¨¡å‹æ­£å¼å‘å¸ƒï¼ï¼ï¼
## ç®€ä»‹
   åœ¨å­¦æœ¯ç•Œï¼Œä¸€äº›ç ”ç©¶å›¢é˜Ÿå¼€å§‹å°è¯•å°†Langchainçš„æ€æƒ³åº”ç”¨äºæœ¬åœ°çŸ¥è¯†åº“çš„æ„å»ºã€‚ä»–ä»¬è‡´åŠ›äºé€šè¿‡æ„å»ºçŸ¥è¯†å›¾è°±ã€æ•´åˆé¢†åŸŸä¸“å®¶çŸ¥è¯†ç­‰æ–¹å¼ï¼Œå»ºç«‹èµ·ä¸°å¯Œçš„æœ¬åœ°çŸ¥è¯†åº“ï¼Œå¹¶ç»“åˆå¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡Œé—®é¢˜å›ç­”ã€‚è¿™äº›ç ”ç©¶æ—¨åœ¨æé«˜é—®ç­”ç³»ç»Ÿå¯¹ä¸­æ–‡è¯­å¢ƒçš„ç†è§£å’Œå¤„ç†èƒ½åŠ›ï¼Œä½¿å…¶èƒ½å¤Ÿæ›´å‡†ç¡®åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚æœ¬æ–‡å°±æ˜¯åŸºäºLangchainæ¡†æ¶æ„å»ºæœ¬åœ°çš„çŸ¥è¯†åº“å¹¶æ¥å…¥LLMæ¨¡å‹æ¥æ„å»ºçš„ä¸€ä¸ªå®£ä¼ å‘¼å’Œæµ©ç‰¹æ–‡åŒ–çš„å¯¹è¯é—®ç­”ç³»ç»Ÿã€‚
<p align="center">
    <img src="./figure/Langchain.jpeg" width=900px/>
</p>

æˆ‘ä»¬é€‰æ‹©äº† [InternLMå¤§è¯­è¨€æ¨¡å‹](https://github.com/InternLM/InternLM) ä½œä¸ºåº•åº§å¤§è¯­è¨€æ¨¡å‹ï¼Œè¿›è¡Œäº†**æœ¬åœ°çŸ¥è¯†åº“çš„æ¥å…¥**ï¼Œæ—¨åœ¨æå‡æ¨¡å‹çš„é’ˆå¯¹å‘¼å’Œæµ©ç‰¹åœ°åŒºçš„äº¤æµé—®ç­”èƒ½åŠ›ã€‚ä¹‹æ‰€ä»¥é€‰æ‹©InternLMæ¨¡å‹åŸå› å¦‚ä¸‹ï¼š
## Introduction

InternLM2 series are released with the following features:

- **200K Context window**: Nearly perfect at finding needles in the haystack with 200K-long context, with leading performance on long-context tasks like LongBench and L-Eval. Try it with [LMDeploy](./chat/lmdeploy.md) for 200K-context inference.

- **Outstanding comprehensive performance**: Significantly better than the last generation in all dimensions, especially in reasoning, math, code, chat experience, instruction following, and creative writing, with leading performance among open-source models in similar sizes. In some evaluations, InternLM2-Chat-20B may match or even surpass ChatGPT (GPT-3.5).

- **Code interpreter & Data analysis**: With code interpreter, InternLM2-Chat-20B obtains compatible performance with GPT-4 on GSM8K and MATH. InternLM2-Chat also provides data analysis capability.

- **Stronger tool use**: Based on better tool utilization-related capabilities in instruction following, tool selection and reflection, InternLM2 can support more kinds of agents and multi-step tool calling for complex tasks. See [examples](./agent/).

## Model Zoo

| Model                      | Transformers(HF)                           | ModelScope(HF)                           | OpenXLab(HF)                           | OpenXLab(Origin)                           | Release Date |
| -------------------------- | ------------------------------------------ | ---------------------------------------- | -------------------------------------- | ------------------------------------------ | ------------ |
| **InternLM2-1.8B**     | [ğŸ¤—internlm2-1.8b](https://huggingface.co/internlm/internlm2-1_8b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-1.8b](https://www.modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-1_8b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-1.8b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-1.8b-original) | 2024-01-31   |
| **InternLM2-Chat-1.8B-SFT**          | [ğŸ¤—internlm2-chat-1.8b-sft](https://huggingface.co/internlm/internlm2-chat-1_8b-sft) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-chat-1.8b-sft](https://www.modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-1_8b-sft/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-1.8b-sft) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-1.8b-sft-original) | 2024-01-31   |
| **InternLM2-Chat-1.8B**          | [ğŸ¤—internlm2-chat-1.8b](https://huggingface.co/internlm/internlm2-chat-1_8b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-chat-1.8b](https://www.modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-1_8b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-1.8b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-1.8b-original) | 2024-02-19   |
| **InternLM2-Base-7B**      | [ğŸ¤—internlm2-base-7b](https://huggingface.co/internlm/internlm2-base-7b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-base-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-base-7b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-7b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-7b-original) | 2024-01-17   |
| **InternLM2-7B**           | [ğŸ¤—internlm2-7b](https://huggingface.co/internlm/internlm2-7b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-7b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-7b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-7b-original) | 2024-01-17   |
| **InternLM2-Chat-7B-SFT**  | [ğŸ¤—internlm2-chat-7b-sft](https://huggingface.co/internlm/internlm2-chat-7b-sft) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-chat-7b-sft](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-7b-sft/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-7b-sft) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-7b-sft-original) | 2024-01-17   |
| **InternLM2-Chat-7B**      | [ğŸ¤—internlm2-chat-7b](https://huggingface.co/internlm/internlm2-chat-7b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-chat-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-7b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-7b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-7b-original) | 2024-01-17   |
| **InternLM2-Base-20B**     | [ğŸ¤—internlm2-base-20b](https://huggingface.co/internlm/internlm2-base-20b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-base-20b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-base-20b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-20b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-base-20b-original) | 2024-01-17   |
| **InternLM2-20B**          | [ğŸ¤—internlm2-20b](https://huggingface.co/internlm/internlm2-20b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-20b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-20b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-20b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-20b-original) | 2024-01-17   |
| **InternLM2-Chat-20B-SFT** | [ğŸ¤—internlm2-chat-20b-sft](https://huggingface.co/internlm/internlm2-chat-20b-sft) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-chat-20b-sft](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-20b-sft/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-20b-sft) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-20b-sft-original) | 2024-01-17   |
| **InternLM2-Chat-20B**     | [ğŸ¤—internlm2-chat-20b](https://huggingface.co/internlm/internlm2-chat-20b) | [<img src="./figure/modelscope_logo.png" width="20px" /> internlm2-chat-20b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm2-chat-20b/summary) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-20b) | [![Open in OpenXLab](https://cdn-static.openxlab.org.cn/header/openxlab_models.svg)](https://openxlab.org.cn/models/detail/OpenLMLab/internlm2-chat-20b-original) | 2024-01-17   |


## ä½¿ç”¨æ–¹æ³•
* å…‹éš†æœ¬é¡¹ç›®
```bash
cd ~
git clone https://github.com/R2-xurongjian/my_HohhotLLM.git
```
* ä¸‹è½½æ¨¡å‹    
æœ¬é¡¹ç›®ä½¿ç”¨çš„LLMæ¨¡å‹ä¸ºå¤æ—¦å¤§å­¦ç ”å‘çš„InternLMï¼ˆä¹¦ç”ŸÂ·æµ¦è¯­ï¼‰å¤§è¯­è¨€æ¨¡å‹ï¼Œå»ºè®®æ‰‹åŠ¨åœ¨huggingfaceä¸Šä¸‹è½½æ¨¡å‹ä¹Ÿå¯ä»¥gitä¸‹è½½
```
git clone https://huggingface.co/internlm/internlm2-chat-7b
```

* åˆ›å»ºå¹¶æ¿€æ´»condaç¯å¢ƒ    
è¿™é‡Œæˆ‘ä¸åšå…·ä½“çš„è™šæ‹Ÿcondaç¯å¢ƒçš„åˆ›å»º
```
conda activate InternLM
```

* å®‰è£…Langchainç›¸å…³ä¾èµ–
```
pip install langchain==0.0.292
pip install gradio==4.4.0
pip install chromadb==0.4.15
pip install sentence-transformers==2.2.2
pip install unstructured==0.10.30
pip install markdown==3.3.7
```
* ä¸‹è½½å¼€æºè¯å‘é‡æ¨¡å‹    
åŒæ—¶ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨åˆ°å¼€æºè¯å‘é‡æ¨¡å‹ [Sentence Transformer](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2):ï¼ˆæˆ‘ä»¬ä¹Ÿå¯ä»¥é€‰ç”¨åˆ«çš„å¼€æºè¯å‘é‡æ¨¡å‹æ¥è¿›è¡Œ Embeddingï¼Œç›®å‰é€‰ç”¨è¿™ä¸ªæ¨¡å‹æ˜¯ç›¸å¯¹    è½»é‡ã€æ”¯æŒä¸­æ–‡ä¸”æ•ˆæœè¾ƒå¥½çš„ï¼‰

* é¦–å…ˆéœ€è¦ä½¿ç”¨ `huggingface` å®˜æ–¹æä¾›çš„ `huggingface-cli` å‘½ä»¤è¡Œå·¥å…·ã€‚å®‰è£…ä¾èµ–:

```
pip install -U huggingface_hub
```

* ç„¶ååœ¨æ ¹ç›®å½•ä¸‹æ–°å»ºpythonæ–‡ä»¶ `download.py`ï¼Œå¡«å…¥ä»¥ä¸‹ä»£ç ï¼š
```python
import os
* è¿è¡Œdownload.pyè¿›è¡Œä¸‹è½½

# ä¸‹è½½æ¨¡å‹
os.system('huggingface-cli download --resume-download sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 --local-dir /root/data/model/sentence-transformer')
```
* ä¸‹è½½ NLTK ç›¸å…³èµ„æº    
æˆ‘ä»¬åœ¨ä½¿ç”¨å¼€æºè¯å‘é‡æ¨¡å‹æ„å»ºå¼€æºè¯å‘é‡çš„æ—¶å€™ï¼Œéœ€è¦ç”¨åˆ°ç¬¬ä¸‰æ–¹åº“ `nltk` çš„ä¸€äº›èµ„æºã€‚æ­£å¸¸æƒ…å†µä¸‹ï¼Œå…¶ä¼šè‡ªåŠ¨ä»äº’è”ç½‘ä¸Šä¸‹è½½ï¼Œä½†å¯èƒ½ç”±äºç½‘ç»œåŸå› ä¼šå¯¼è‡´ä¸‹è½½ä¸­æ–­ï¼Œæ­¤å¤„æˆ‘ä»¬å¯ä»¥ä»å›½å†…ä»“åº“é•œåƒåœ°å€ä¸‹è½½ç›¸å…³èµ„æºï¼Œä¿å­˜åˆ°æœåŠ¡å™¨ä¸Šã€‚
æˆ‘ä»¬ç”¨ä»¥ä¸‹å‘½ä»¤ä¸‹è½½ nltk èµ„æºå¹¶è§£å‹åˆ°æœåŠ¡å™¨ä¸Šï¼š


```bash
cd /root
git clone https://gitee.com/yzy0612/nltk_data.git  --branch gh-pages
cd nltk_data
mv packages/*  ./
cd tokenizers
unzip punkt.zip
cd ../taggers
unzip averaged_perceptron_tagger.zip
```

* å®‰è£…è¿è¡Œdemoæ‰€éœ€è¦çš„ä¾èµ–
```shell
# å‡çº§pip
python -m pip install --upgrade pip

pip install modelscope==1.9.5
pip install transformers==4.35.2
pip install streamlit==1.24.0
pip install sentencepiece==0.1.99
pip install accelerate==0.24.1
```
   
* å¯åŠ¨æœåŠ¡     
æœ¬é¡¹ç›®æä¾›äº†[run_gradio.py](./run_gradio.py)ä½œä¸ºæ¨¡å‹çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œæ¥é€šè¿‡ python å‘½ä»¤è¿è¡Œï¼Œå³å¯åœ¨æœ¬åœ°å¯åŠ¨çŸ¥è¯†åº“åŠ©æ‰‹çš„ Web Demoï¼Œé»˜è®¤ä¼šåœ¨ 7860 ç«¯å£è¿è¡Œï¼Œæ¥ä¸‹æ¥å°†æœåŠ¡å™¨ç«¯å£æ˜ å°„åˆ°æœ¬åœ°ç«¯å£å³å¯è®¿é—®
```
python run_gradio.py
```

## ç¤ºä¾‹
* æ•´ä½“å¸ƒå±€
<p align="center">
    <img src="./figure/æ•´ä½“å¸ƒå±€.png" width=900px/>
</p>  

* æ ·ä¾‹1ï¼šä»‹ç»ä¸€ä¸‹å‘¼å’Œæµ©ç‰¹çš„æ–‡åŒ–
<p align="center">
    <img src="./figure/æ–‡åŒ–2.png" width=900px/>
</p>

* æ ·ä¾‹2ï¼šä»‹ç»ä¸€ä¸‹å‘¼å’Œæµ©ç‰¹çš„å¤§æ˜­å¯º

<p align="center">
    <img src="./figure/å¤§æ˜­å¯º.png" width=900px/>
</p>

* æ ·ä¾‹3ï¼šå†…è’™å¤å¤§å­¦åœ¨å‘¼å’Œæµ©ç‰¹çš„ä½ç½®

<p align="center">
    <img src="./figure/å†…è’™å¤å¤§å­¦.png" width=900px/>
</p>

## å¯¹æ¯”åˆ†æ
#### å†…è’™å¤å¤§å­¦åœ¨å‘¼å’Œæµ©ç‰¹çš„ä½ç½®
* GPT3.5ç”Ÿæˆ
<p align="center">
    <img src="./figure/GPT2.png" width=900px/>
</p>
* æœ¬é¡¹ç›®ç”Ÿæˆ
<p align="center">
    <img src="./figure/å†…è’™å¤å¤§å­¦.png" width=900px/>
</p>

#### ä»‹ç»ä¸€ä¸‹å‘¼å’Œæµ©ç‰¹çš„å¤§æ˜­å¯º
* GPT3.5ç”Ÿæˆ
<p align="center">
    <img src="./figure/GPT1.png" width=900px/>
</p>
* æœ¬é¡¹ç›®ç”Ÿæˆ
<p align="center">
    <img src="./figure/å¤§æ˜­å¯º.png" width=900px/>
</p>
å¯ä»¥çœ‹å‡ºæœ¬é¡¹ç›®åœ¨é’ˆå¯¹å‘¼å’Œæµ©ç‰¹åŒºåŸŸçš„æ–‡åŒ–ä¸Šè¿˜æ˜¯è¾ƒä¸ºå‡†ç¡®çš„ï¼Œç›¸æ¯”äºç«çˆ†GPT3.5è¦æ›´ä¼˜è¶Šã€‚

## å£°æ˜
* æœ¬é¡¹ç›®ä½¿ç”¨äº†IntertnLMæ¨¡å‹çš„æƒé‡ï¼Œéœ€è¦éµå¾ªå…¶[LICENSE](https://github.com/InternLM/InternLM/blob/main/LICENSE)ï¼Œå› æ­¤ï¼Œ**æœ¬é¡¹ç›®ä»…å¯ç”¨äºæ‚¨çš„éå•†ä¸šç ”ç©¶ç›®çš„**ã€‚
* æœ¬é¡¹ç›®æä¾›çš„å¯¹è¯é—®ç­”æ¨¡å‹è‡´åŠ›äºæå‡ç”¨æˆ·å¯¹å‘¼å’Œæµ©ç‰¹åŒºåŸŸçŸ¥è¯†çš„äº†è§£ä»¥åŠä½¿ç”¨Langchainæ¡†æ¶æ„å»ºæœ¬åœ°çŸ¥è¯†åº“çš„ä½¿ç”¨ã€‚æœ¬é¡¹ç›®ä¸ä¿è¯æ¨¡å‹è¾“å‡ºçš„æ–‡æœ¬å®Œå…¨é€‚åˆäºç”¨æˆ·ï¼Œç”¨æˆ·åœ¨ä½¿ç”¨æœ¬æ¨¡å‹æ—¶éœ€è¦æ‰¿æ‹…å…¶å¸¦æ¥çš„æ‰€æœ‰é£é™©ï¼
* æ‚¨ä¸å¾—å‡ºäºä»»ä½•å•†ä¸šã€å†›äº‹æˆ–éæ³•ç›®çš„ä½¿ç”¨ã€å¤åˆ¶ã€ä¿®æ”¹ã€åˆå¹¶ã€å‘å¸ƒã€åˆ†å‘ã€å¤åˆ¶æˆ–åˆ›å»ºHohhotLLMçš„å…¨éƒ¨æˆ–éƒ¨åˆ†è¡ç”Ÿä½œå“ã€‚
* æ‚¨ä¸å¾—åˆ©ç”¨HohhotLLMæ¨¡å‹ä»äº‹ä»»ä½•å±å®³å›½å®¶å®‰å…¨å’Œå›½å®¶ç»Ÿä¸€ã€å±å®³ç¤¾ä¼šå…¬å…±åˆ©ç›Šã€ä¾µçŠ¯äººèº«æƒç›Šçš„è¡Œä¸ºã€‚

## è‡´è°¢
æœ¬é¡¹ç›®ç”±å†…è’™å¤å¤§å­¦è®¡ç®—æœºå­¦é™¢ï¼ˆè½¯ä»¶å­¦é™¢ï¼‰å¾è£å»ºå‘èµ·ï¼Œå¾—åˆ°äº†å†…è’™å¤å¤§å­¦è®¡ç®—æœºå­¦é™¢ï¼ˆè½¯ä»¶å­¦é™¢ï¼‰åˆ˜ç‘å®éªŒå®¤çš„æ”¯æ’‘ï¼ŒåŒæ—¶è‡´è°¢å†…è’™å¤å¤§å­¦è®¡ç®—æœºå­¦é™¢ã€‚

